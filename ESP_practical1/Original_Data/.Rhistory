sample_50_words
Frenquency_table <- as.data.frame(table(all_words[, 3]))
Frenquency_table <- as.data.frame(table(all_third_words[, 3]))
Frenquency_table$word_freq <- Frenquency_table[, 2] / sum(Frenquency_table[, 2])
Frenquency_table
all_third_words <- matrix(Tri_final[(Tri_final[, 1] == 503) &
(Tri_final[, 2] == 240),], ncol = 3)
c <- as.data.frame(table(all_third_words[,3]))
c$word_freq <- c[, 2] / sum(c[, 2])
c
sample(as.integer(as.character(Frenquency_table[, 1])), size = 1, prob = Frenquency_table$word_freq)
Frenquency_table$word_freq
Frenquency_table[, 1])
Frenquency_table[, 1]
as.integer(as.character(Frenquency_table[, 1]))
# Modified Version 1
sample_words <- function(all_words, n) {
Frenquency_table <- as.data.frame(table(all_words[, -1]))
Frenquency_table$word_freq <- Frenquency_table[, 2] / sum(Frenquency_table[, 2])
index_TEMP <- as.integer(as.character(Frenquency_table[, 1]))
if (length(index_TEMP) == 1) {
index_temp <- index_TEMP
} else {
index_temp <- sample(index_TEMP, size = n, prob = as.double(Frenquency_table$word_freq))
}
return(index_temp)
}
sample_50_words <- c() ## vector for 50-word sections
sample_50_words[1] <- sample(unique(P_final[, 1]), size = 1) ## 8(a)randomly select from P_final
all_second_words_1 <- matrix(P_final[P_final[, 1] == sample_50_words[1], ], ncol = 2) ## generate second word from Pairs
# sec_freq <- as.data.frame(table(all_second_words_1))
# sec_freq$word_freq <- sec_freq[, 2] / sum(sec_freq[, 2])
# sample_50_words[2] <- sample(sec_freq[, 1], size = 1, prob = sec_freq$word_freq)
sample_50_words[2] <- sample_words(all_second_words_1, 1)
# Simulate the rest of the 48 words
for (i in 3:50) {
## 8(b) extract sub-matrix[2] from Triplets
all_third_words <- matrix(Tri_final[(Tri_final[, 1] == sample_50_words[i - 2]) &
(Tri_final[, 2] == sample_50_words[i - 1]), ], ncol = 3)
all_second_words <- matrix(P_final[P_final[, 1] == sample_50_words[i - 1], ], ncol = 2)
## 8(c)
if (length(all_third_words) != 0) { ## if sub-matrix has rows
# third_freq <- as.data.frame(table(all_third_words[, 3]))
# third_freq$word_freq <- third_freq[, 2] / sum(third_freq[, 2])
# index_TEMP3 <- as.character(third_freq[, 1])
# index_TEMP3 <- as.integer(index_TEMP3)
# if (length(index_TEMP3) == 1) {
#   index_temp3 <- index_TEMP3
# } else {
#   index_temp3 <- sample(index_TEMP3, size = 1, prob = third_freq[, 3])
# }
index_temp3 <- sample_words(all_third_words, 1, 3)
sample_50_words <- append(sample_50_words, index_temp3) ## simulate from Triplets
cat(i, "3", index_temp3, "\n")
} else if (length(all_second_words) != 0) { ## if sub-matrix has no rows
# second_freq <- as.data.frame(table(all_second_words[, 2]))
# second_freq$word_freq <- second_freq[, 2] / sum(second_freq[, 2])
# index_TEMP2 <- as.character(second_freq[, 1])
# index_TEMP2 <- as.integer(index_TEMP2)
# if (length(index_TEMP2) == 1) {
#   index_temp2 <- index_TEMP2
# } else {
#   index_temp2 <- sample(index_TEMP2, size = 1, prob = second_freq[, 3])
# }
# index_temp2 <- sample(index_TEMP2, size = 1, prob = second_freq[, 3])
index_temp2 <- sample_words(all_second_words, 1, 2)
sample_50_words <- append(sample_50_words, index_temp2) ## simulate from Pairs
cat(i, "2", index_temp2, "\n")
} else { ## if neither Triplets nor Pairs have rows
index_temp1 <- sample(unique(P_final[, 1]), 1)
sample_50_words <- append(sample_50_words, index_temp1) ## simulate based on probability
cat(i, "1", index_temp1, "\n")
}
}
# Modified Version 1
sample_words <- function(all_words, n, type) {
Frenquency_table <- as.data.frame(table(all_words[, type]))
Frenquency_table$word_freq <- Frenquency_table[, 2] / sum(Frenquency_table[, 2])
index_TEMP <- as.integer(as.character(Frenquency_table[, 1]))
if (length(index_TEMP) == 1) {
index_temp <- index_TEMP
} else {
index_temp <- sample(index_TEMP, size = n, prob = as.double(Frenquency_table$word_freq))
}
return(index_temp)
}
sample_50_words <- c() ## vector for 50-word sections
sample_50_words[1] <- sample(unique(P_final[, 1]), size = 1) ## 8(a)randomly select from P_final
all_second_words_1 <- matrix(P_final[P_final[, 1] == sample_50_words[1], ], ncol = 2) ## generate second word from Pairs
# sec_freq <- as.data.frame(table(all_second_words_1))
# sec_freq$word_freq <- sec_freq[, 2] / sum(sec_freq[, 2])
# sample_50_words[2] <- sample(sec_freq[, 1], size = 1, prob = sec_freq$word_freq)
sample_50_words[2] <- sample_words(all_second_words_1, 1)
# Simulate the rest of the 48 words
for (i in 3:50) {
## 8(b) extract sub-matrix[2] from Triplets
all_third_words <- matrix(Tri_final[(Tri_final[, 1] == sample_50_words[i - 2]) &
(Tri_final[, 2] == sample_50_words[i - 1]), ], ncol = 3)
all_second_words <- matrix(P_final[P_final[, 1] == sample_50_words[i - 1], ], ncol = 2)
## 8(c)
if (length(all_third_words) != 0) { ## if sub-matrix has rows
# third_freq <- as.data.frame(table(all_third_words[, 3]))
# third_freq$word_freq <- third_freq[, 2] / sum(third_freq[, 2])
# index_TEMP3 <- as.character(third_freq[, 1])
# index_TEMP3 <- as.integer(index_TEMP3)
# if (length(index_TEMP3) == 1) {
#   index_temp3 <- index_TEMP3
# } else {
#   index_temp3 <- sample(index_TEMP3, size = 1, prob = third_freq[, 3])
# }
index_temp3 <- sample_words(all_third_words, 1, 3)
sample_50_words <- append(sample_50_words, index_temp3) ## simulate from Triplets
cat(i, "3", index_temp3, "\n")
} else if (length(all_second_words) != 0) { ## if sub-matrix has no rows
# second_freq <- as.data.frame(table(all_second_words[, 2]))
# second_freq$word_freq <- second_freq[, 2] / sum(second_freq[, 2])
# index_TEMP2 <- as.character(second_freq[, 1])
# index_TEMP2 <- as.integer(index_TEMP2)
# if (length(index_TEMP2) == 1) {
#   index_temp2 <- index_TEMP2
# } else {
#   index_temp2 <- sample(index_TEMP2, size = 1, prob = second_freq[, 3])
# }
# index_temp2 <- sample(index_TEMP2, size = 1, prob = second_freq[, 3])
index_temp2 <- sample_words(all_second_words, 1, 2)
sample_50_words <- append(sample_50_words, index_temp2) ## simulate from Pairs
cat(i, "2", index_temp2, "\n")
} else { ## if neither Triplets nor Pairs have rows
index_temp1 <- sample(unique(P_final[, 1]), 1)
sample_50_words <- append(sample_50_words, index_temp1) ## simulate based on probability
cat(i, "1", index_temp1, "\n")
}
}
section8 <- paste(b[sample_50_words], collapse = " ") ## combined into a sentence
section8 <- gsub("\\s+(?=[[:punct:]])", "", section8, perl = TRUE)
cat(section8)
sample_50_words
# Modified Version 1
sample_words <- function(all_words, n, type) {
Frenquency_table <- as.data.frame(table(all_words[, type]))
Frenquency_table$word_freq <- Frenquency_table[, 2] / sum(Frenquency_table[, 2])
index_TEMP <- as.integer(as.character(Frenquency_table[, 1]))
if (length(index_TEMP) == 1) {
index_temp <- index_TEMP
} else {
index_temp <- sample(index_TEMP, size = n, prob = as.double(Frenquency_table$word_freq))
}
return(index_temp)
}
sample_50_words <- c() ## vector for 50-word sections
sample_50_words[1] <- sample(unique(P_final[, 1]), size = 1) ## 8(a)randomly select from P_final
all_second_words_1 <- matrix(P_final[P_final[, 1] == sample_50_words[1], ], ncol = 2) ## generate second word from Pairs
# sec_freq <- as.data.frame(table(all_second_words_1))
# sec_freq$word_freq <- sec_freq[, 2] / sum(sec_freq[, 2])
# sample_50_words[2] <- sample(sec_freq[, 1], size = 1, prob = sec_freq$word_freq)
sample_50_words[2] <- sample_words(all_second_words_1, 1)
# Simulate the rest of the 48 words
for (i in 3:50) {
## 8(b) extract sub-matrix[2] from Triplets
all_third_words <- matrix(Tri_final[(Tri_final[, 1] == sample_50_words[i - 2]) &
(Tri_final[, 2] == sample_50_words[i - 1]), ], ncol = 3)
all_second_words <- matrix(P_final[P_final[, 1] == sample_50_words[i - 1], ], ncol = 2)
## 8(c)
if (length(all_third_words) != 0) { ## if sub-matrix has rows
# third_freq <- as.data.frame(table(all_third_words[, 3]))
# third_freq$word_freq <- third_freq[, 2] / sum(third_freq[, 2])
# index_TEMP3 <- as.character(third_freq[, 1])
# index_TEMP3 <- as.integer(index_TEMP3)
# if (length(index_TEMP3) == 1) {
#   index_temp3 <- index_TEMP3
# } else {
#   index_temp3 <- sample(index_TEMP3, size = 1, prob = third_freq[, 3])
# }
index_temp3 <- sample_words(all_third_words, 1, 3)
sample_50_words <- append(sample_50_words, index_temp3) ## simulate from Triplets
cat(i, "3", index_temp3, "\n")
} else if (length(all_second_words) != 0) { ## if sub-matrix has no rows
# second_freq <- as.data.frame(table(all_second_words[, 2]))
# second_freq$word_freq <- second_freq[, 2] / sum(second_freq[, 2])
# index_TEMP2 <- as.character(second_freq[, 1])
# index_TEMP2 <- as.integer(index_TEMP2)
# if (length(index_TEMP2) == 1) {
#   index_temp2 <- index_TEMP2
# } else {
#   index_temp2 <- sample(index_TEMP2, size = 1, prob = second_freq[, 3])
# }
# index_temp2 <- sample(index_TEMP2, size = 1, prob = second_freq[, 3])
index_temp2 <- sample_words(all_second_words, 1, 2)
sample_50_words <- append(sample_50_words, index_temp2) ## simulate from Pairs
cat(i, "2", index_temp2, "\n")
} else { ## if neither Triplets nor Pairs have rows
index_temp1 <- sample(unique(P_final[, 1]), 1)
sample_50_words <- append(sample_50_words, index_temp1) ## simulate based on probability
cat(i, "1", index_temp1, "\n")
}
}
section8 <- paste(b[sample_50_words], collapse = " ") ## combined into a sentence
section8 <- gsub("\\s+(?=[[:punct:]])", "", section8, perl = TRUE)
cat(section8)
# Modified Version 1
sample_words <- function(all_words, n, type) {
Frenquency_table <- as.data.frame(table(all_words[, type]))
Frenquency_table$word_freq <- Frenquency_table[, 2] / sum(Frenquency_table[, 2])
index_TEMP <- as.integer(as.character(Frenquency_table[, 1]))
if (length(index_TEMP) == 1) {
index_temp <- index_TEMP
} else {
index_temp <- sample(index_TEMP, size = n, prob = as.double(Frenquency_table$word_freq))
}
return(index_temp)
}
sample_50_words <- c() ## vector for 50-word sections
sample_50_words[1] <- sample(unique(P_final[, 1]), size = 1) ## 8(a)randomly select from P_final
all_second_words_1 <- matrix(P_final[P_final[, 1] == sample_50_words[1], ], ncol = 2) ## generate second word from Pairs
# sec_freq <- as.data.frame(table(all_second_words_1))
# sec_freq$word_freq <- sec_freq[, 2] / sum(sec_freq[, 2])
# sample_50_words[2] <- sample(sec_freq[, 1], size = 1, prob = sec_freq$word_freq)
sample_50_words[2] <- sample_words(all_second_words_1, 1)
# Simulate the rest of the 48 words
for (i in 3:50) {
## 8(b) extract sub-matrix[2] from Triplets
all_third_words <- matrix(Tri_final[(Tri_final[, 1] == sample_50_words[i - 2]) &
(Tri_final[, 2] == sample_50_words[i - 1]), ], ncol = 3)
all_second_words <- matrix(P_final[P_final[, 1] == sample_50_words[i - 1], ], ncol = 2)
## 8(c)
if (length(all_third_words) != 0) { ## if sub-matrix has rows
# third_freq <- as.data.frame(table(all_third_words[, 3]))
# third_freq$word_freq <- third_freq[, 2] / sum(third_freq[, 2])
# index_TEMP3 <- as.character(third_freq[, 1])
# index_TEMP3 <- as.integer(index_TEMP3)
# if (length(index_TEMP3) == 1) {
#   index_temp3 <- index_TEMP3
# } else {
#   index_temp3 <- sample(index_TEMP3, size = 1, prob = third_freq[, 3])
# }
index_temp3 <- sample_words(all_third_words, 1, 3)
sample_50_words <- append(sample_50_words, index_temp3) ## simulate from Triplets
cat(i, "3", index_temp3, "\n")
} else if (length(all_second_words) != 0) { ## if sub-matrix has no rows
# second_freq <- as.data.frame(table(all_second_words[, 2]))
# second_freq$word_freq <- second_freq[, 2] / sum(second_freq[, 2])
# index_TEMP2 <- as.character(second_freq[, 1])
# index_TEMP2 <- as.integer(index_TEMP2)
# if (length(index_TEMP2) == 1) {
#   index_temp2 <- index_TEMP2
# } else {
#   index_temp2 <- sample(index_TEMP2, size = 1, prob = second_freq[, 3])
# }
# index_temp2 <- sample(index_TEMP2, size = 1, prob = second_freq[, 3])
index_temp2 <- sample_words(all_second_words, 1, 2)
sample_50_words <- append(sample_50_words, index_temp2) ## simulate from Pairs
cat(i, "2", index_temp2, "\n")
} else { ## if neither Triplets nor Pairs have rows
index_temp1 <- sample(unique(P_final[, 1]), 1)
sample_50_words <- append(sample_50_words, index_temp1) ## simulate based on probability
cat(i, "1", index_temp1, "\n")
}
}
section8 <- paste(b[sample_50_words], collapse = " ") ## combined into a sentence
section8 <- gsub("\\s+(?=[[:punct:]])", "", section8, perl = TRUE)
cat(section8)
sample_50_words
all_third_words <- matrix(Tri_final[(Tri_final[, 1] == 570) &
(Tri_final[, 2] == 230),], ncol = 3)
c <- as.data.frame(table(all_third_words[,3]))
c$word_freq <- c[, 2] / sum(c[, 2])
c
all_second_words <- matrix(P_final[P_final[, 1] == 16,], ncol = 2)
c <- as.data.frame(table(all_second_words[,2]))
c$word_freq <- c[, 2] / sum(c[, 2])
c
matrix(Tri_final[(Tri_final[, 1] == sample_50_words[i - 2]) &
(Tri_final[, 2] == sample_50_words[i - 1]),], ncol = 3)
all_third_words <- matrix(Tri_final[(Tri_final[, 1] == 16) &
(Tri_final[, 2] == 2),], ncol = 3)
c <- as.data.frame(table(all_third_words[,3]))
c$word_freq <- c[, 2] / sum(c[, 2])
c
c
sample(c[, 1], size = 1, prob = c$word_freq)
all_third_words <- matrix(Tri_final[(Tri_final[, 1] == 2) &
(Tri_final[, 2] == 101),], ncol = 3)
c <- as.data.frame(table(all_third_words[,3]))
c$word_freq <- c[, 2] / sum(c[, 2])
c
sample(c[, 1], size = 1, prob = c$word_freq)
# Modified Version 1
sample_words <- function(all_words, n, type) {
Frenquency_table <- as.data.frame(table(all_words[, type]))
Frenquency_table$word_freq <- Frenquency_table[, 2] / sum(Frenquency_table[, 2])
index_TEMP <- as.integer(as.character(Frenquency_table[, 1]))
if (length(index_TEMP) == 1) {
index_temp <- index_TEMP
} else {
index_temp <- sample(index_TEMP, size = n, prob = as.double(Frenquency_table$word_freq))
}
return(index_temp)
}
sample_50_words <- c() ## vector for 50-word sections
sample_50_words[1] <- sample(unique(P_final[, 1]), size = 1) ## 8(a)randomly select from P_final
# all_second_words_1 <- matrix(P_final[P_final[, 1] == sample_50_words[1], ], ncol = 2) ## generate second word from Pairs
# sec_freq <- as.data.frame(table(all_second_words_1))
# sec_freq$word_freq <- sec_freq[, 2] / sum(sec_freq[, 2])
# sample_50_words[2] <- sample(sec_freq[, 1], size = 1, prob = sec_freq$word_freq)
sample_50_words[2] <- sample_words(matrix(P_final[P_final[, 1] == sample_50_words[1], ], ncol = 2), 1)
# Simulate the rest of the 48 words
for (i in 3:50) {
## 8(b) extract sub-matrix[2] from Triplets
all_third_words <- matrix(Tri_final[(Tri_final[, 1] == sample_50_words[i - 2]) &
(Tri_final[, 2] == sample_50_words[i - 1]), ], ncol = 3)
all_second_words <- matrix(P_final[P_final[, 1] == sample_50_words[i - 1], ], ncol = 2)
## 8(c)
if (length(all_third_words) != 0) { ## if sub-matrix has rows
# third_freq <- as.data.frame(table(all_third_words[, 3]))
# third_freq$word_freq <- third_freq[, 2] / sum(third_freq[, 2])
# index_TEMP3 <- as.character(third_freq[, 1])
# index_TEMP3 <- as.integer(index_TEMP3)
# if (length(index_TEMP3) == 1) {
#   index_temp3 <- index_TEMP3
# } else {
#   index_temp3 <- sample(index_TEMP3, size = 1, prob = third_freq[, 3])
# }
# index_temp3 <- sample_words(all_third_words, 1, 3)
# sample_50_words <- append(sample_50_words, index_temp3) ## simulate from Triplets
sample_50_words <- append(sample_50_words, sample_words(all_third_words, 1, 3))
cat(i, "3", index_temp3, "\n")
} else if (length(all_second_words) != 0) { ## if sub-matrix has no rows
# second_freq <- as.data.frame(table(all_second_words[, 2]))
# second_freq$word_freq <- second_freq[, 2] / sum(second_freq[, 2])
# index_TEMP2 <- as.character(second_freq[, 1])
# index_TEMP2 <- as.integer(index_TEMP2)
# if (length(index_TEMP2) == 1) {
#   index_temp2 <- index_TEMP2
# } else {
#   index_temp2 <- sample(index_TEMP2, size = 1, prob = second_freq[, 3])
# }
# index_temp2 <- sample(index_TEMP2, size = 1, prob = second_freq[, 3])
# index_temp2 <- sample_words(all_second_words, 1, 2)
# sample_50_words <- append(sample_50_words, index_temp2) ## simulate from Pairs
sample_50_words <- append(sample_50_words, sample_words(all_second_words, 1, 2)) ## simulate from Pairs
cat(i, "2", index_temp2, "\n")
} else { ## if neither Triplets nor Pairs have rows
# index_temp1 <- sample(unique(P_final[, 1]), 1)
# sample_50_words <- append(sample_50_words, index_temp1) ## simulate based on probability
sample_50_words <- append(sample_50_words, sample(unique(P_final[, 1]), 1)) ## simulate based on probability
cat(i, "1", index_temp1, "\n")
}
}
section8 <- paste(b[sample_50_words], collapse = " ") ## combined into a sentence
section8 <- gsub("\\s+(?=[[:punct:]])", "", section8, perl = TRUE)
cat(section8)
sample_50_words
Frequency_1000[, 1]
View(Frequency_1000)
# ———————————————————————————————————————————————————————————————————————————————
# Step 9
# ———————————————————————————————————————————————————————————————————————————————
# Frequency_1000$b_freq <- Frequency_1000$Freq / sum(Frequency_1000$Freq)
words_sections9 <- sample(Frequency_1000[, 1], 50, Frequency_1000[, 2]) ## simulate indices based on common frequencies
words_sections9 <- Unique[words_sections9] ## words based on simulation indices
# ———————————————————————————————————————————————————————————————————————————————
# Step 9
# ———————————————————————————————————————————————————————————————————————————————
# Frequency_1000$b_freq <- Frequency_1000$Freq / sum(Frequency_1000$Freq)
words_sections9 <- sample(Frequency_1000[, 1], size = 50, prob = Frequency_1000[, 2]) ## simulate indices based on common frequencies
words_sections9 <- Unique[words_sections9] ## words based on simulation indices
section9 <- paste(words_sections9, collapse = " ") ## combined into a sentence
section9 <- gsub("\\s+(?=[[:punct:]])", "", section9, perl = TRUE)
cat(section9)
styler:::style_active_file()
styler:::style_active_file()
styler:::style_active_file()
# Huantong Hou (s2481591), Yuqi Shi (s2508879), Zukai Li (s2505721)
# Contribution:
#### Huantong Hou (s2481591): 32%
###### (1) Ditch whole idea for total practical work;
###### (2) Finish codes for steps 4, 6 and 10, and participate in debugging total practical work;
###### (3) Participate in making comments on total practical work.
#### Yuqi Shi (s2508879): 33%
###### (1) Organize the logic for implementing the project；
###### (2) Mainly write the code for steps 6, 7, and 8，and participate in debugging work;
###### (3) Participate in making comments on total practical work.
#### Zukai Li (s2505721): 35%
###### (1) Organizing the overall idea of the project；
###### (2) Mainly write the code for steps 4, 8, and 9，and participate in debugging work;
###### (3) Participate in making comments on total practical work.
# ———————————————————————————————————————————————————————————————————————————————
# Step 3
# Read the file into R and remove "_()_"from file
# ———————————————————————————————————————————————————————————————————————————————
# setwd("/Users/shiyuqi/Downloads") ## comment out of submitted
W <- scan("4300-0.txt", what = "character", skip = 73, nlines = 32858 - 73)
W <- gsub("_(", "", W, fixed = TRUE) ## remove "_("
W <- gsub(")_", "", W, fixed = TRUE) ## remove ")_"
# ———————————————————————————————————————————————————————————————————————————————
# Step 4
# Write a function(split_punct) that can find punctuation marks, remove them from words,
# and place separated words and punctuation into a new vector
# ——————————————————————————————————————————————————————————————————————————————
## Remove useless punctuation
remove_punctuation <- function(words) {
words <- gsub("[-—_*()\\.{3}]", "", words) ## remove "[()*-—_]"
words <- words[words != ""] ## remove null
return(words)
}
W <- remove_punctuation(W)
## Write a function(split_punct)
split_punct <- function(words, punctuation) {
words_index <- grep("[,.;!:?]", words) ## indices of words containing "[,.;!:?]"
punc_index <- words_index + 1:length(words_index) ## determine the length of the vector which words and punctuation will be placed
words_modified <- rep("", length(words) + length(punc_index)) ## create a vector to store split words and punctuation
words_modified[-punc_index] <- sapply(words, function(x) ifelse(x %in% words[words_index], substr(x, 1, nchar(x) - 1), x))
## insert the text portion of words
words_modified[punc_index] <- sapply(words[words_index], function(x) substr(x, nchar(x), nchar(x))) ## insert words without punctuation
return(words_modified)
}
# ———————————————————————————————————————————————————————————————————————————————
# Step 5
# Use the split_punct () to separate text and punctuation
# ———————————————————————————————————————————————————————————————————————————————
W_clean <- split_punct(W, punctuation)
# ———————————————————————————————————————————————————————————————————————————————
# Step 6
# Create a vector-b, of the almost 1000 commonly occurring words
# ———————————————————————————————————————————————————————————————————————————————
Unique <- unique(tolower(W_clean)) ## find the unique words of W_clean
Index <- match(tolower(W_clean), Unique) ## find the indicating positions of words in the text corresponding to unique vector
Frequency <- as.data.frame(table(Index)) ## frequency of unique words in the text
sorted_Frequency <- Frequency[order(-Frequency$Freq), ] ## sort frequency in descending order
threshold <- sorted_Frequency$Freq[1000] ## set the threshold number of occurrences
boundary <- max(which(sorted_Frequency$Freq == threshold))
Frequency_1000 <- sorted_Frequency[1:boundary, ]
b <- Unique[Frequency_1000$Index] ## most commonly occurring words
# ———————————————————————————————————————————————————————————————————————————————
# Step 7
# Create the matrices of common word triplets and pairs(Tri_final and P_final)
# ———————————————————————————————————————————————————————————————————————————————
first_col <- second_col <- third_col <- c() ## define empty vectors for three column matrix
Index_a_common <- match(tolower(W_clean), b) ## find the indicating positions of words in the text corresponds to b
for (i in 1:length(Frequency_1000$Index)) {
a_b_position <- which(Index_a_common[] == Frequency_1000$Index[i]) ## find the positions of common words in W_clean
first_col <- as.numeric(append(matrix(rep(Frequency_1000$Index[i], length(a_b_position)), ncol = 1), first_col)) ## index of the common words
second_col <- as.numeric(append(matrix(Index_a_common[a_b_position + 1], ncol = 1), second_col)) ## index for the following word
third_col <- as.numeric(append(matrix(Index_a_common[a_b_position + 2], ncol = 1), third_col)) ## index for the next following word
}
Tri <- cbind(first_col, second_col, third_col) ## define Triplets
Tri_rowsum <- rowSums(Tri, na.rm = FALSE) ## Use rowSum() to find rows that contain 'NA'
Tri_final <- Tri[which(!is.na(Tri_rowsum)), ] ## drop triplets containing NA
## 7(d)same for Pairs
P <- cbind(first_col, second_col)
P_rowsum <- rowSums(P, na.rm = FALSE)
P_final <- P[which(!is.na(P_rowsum)), ]
## remove specific illogical situations in Pairs & Triplets
the_position <- which(b[] == "the") ## find the index of 'the'
position <- which(P_final[, 1] == the_position & P_final[, 2] == the_position) ## find the positions of 'the''the' in pairs
P_final <- P_final[-position, ] ## remove 'the the' from pairs
# ———————————————————————————————————————————————————————————————————————————————
# Step 8
# Simulate 50-word sections using word occurrence probability models
# ———————————————————————————————————————————————————————————————————————————————
## A function randomly extracts word indices from the corresponding array according to different situations
sample_words <- function(all_words, n, type) {
Frenquency_table <- as.data.frame(table(all_words[, type])) ## calculate frequency
Frenquency_table$word_freq <- Frenquency_table[, 2] / sum(Frenquency_table[, 2]) ## calculate sample probability according to the frequency
index_TEMP <- as.integer(as.character(Frenquency_table[, 1])) ## change the data type to make sure the sample function works
if (length(index_TEMP) == 1) { ## when the word to be generated is unique
index_temp <- index_TEMP ## extract directly
} else {
index_temp <- sample(index_TEMP, size = n, prob = as.double(Frenquency_table$word_freq)) ## extract the next generated word based on probability
}
return(index_temp)
}
sample_50_words <- c() ## generate an empty vector for 50-word sections
sample_50_words[1] <- sample(unique(P_final[, 1]), size = 1) ## simulate the first word randomly from P_final
sample_50_words[2] <- sample_words(matrix(P_final[P_final[, 1] == sample_50_words[1], ], ncol = 2), 1) ## simulate the second word randomly
# Simulate the rest of the 48 words
for (i in 3:50) {
all_third_words <- matrix(Tri_final[(Tri_final[, 1] == sample_50_words[i - 2]) &
(Tri_final[, 2] == sample_50_words[i - 1]), ], ncol = 3)
all_second_words <- matrix(P_final[P_final[, 1] == sample_50_words[i - 1], ], ncol = 2)
if (length(all_third_words) != 0) { ## if sub-matrix from Tri_final has rows that satisfy the condition
sample_50_words <- append(sample_50_words, sample_words(all_third_words, 1, 3)) ## simulate from Tri_final
} else if (length(all_second_words) != 0) { ## if sub-matrix from P_final has rows that satisfy the condition
sample_50_words <- append(sample_50_words, sample_words(all_second_words, 1, 2)) ## simulate from Pairs
} else { ## if neither Triplets nor Pairs have rows that satisfy the condition
sample_50_words <- append(sample_50_words, sample(unique(P_final[, 1]), 1)) ## simulate according to the common word frequencies
}
}
section8 <- paste(b[sample_50_words], collapse = " ") ## combined into a sentence
section8 <- gsub("\\s+(?=[[:punct:]])", "", section8, perl = TRUE) ## handling syntactic formatting
cat(section8)
# ———————————————————————————————————————————————————————————————————————————————
# Step 9
# Simulate 50-word sections of text only based on the common word frequencies
# ———————————————————————————————————————————————————————————————————————————————
words_sections9 <- sample(Frequency_1000[, 1], size = 50, prob = Frequency_1000[, 2]) ## simulate indices based on common frequencies
words_sections9 <- Unique[words_sections9] ## find the corresponding words based on simulation indices
section9 <- paste(words_sections9, collapse = " ") ## combined all simulated words into a sentence
section9 <- gsub("\\s+(?=[[:punct:]])", "", section9, perl = TRUE) ## handling syntactic formatting
cat(section9)
# ———————————————————————————————————————————————————————————————————————————————
# Step 10
# Find words that most often start with capital letter, also start with a
# capital letter in simulation (section in step 8)
# ———————————————————————————————————————————————————————————————————————————————
CapitalWords <- c() ## vector for words most often start with capital letter
Capital_Unique <- unique(W_clean) ## Find unique words in text
pattern <- "\\b^[A-Z]\\w*\\b" ## pattern to search words starting with capital letter
for (w in Capital_Unique) {
matches <- str_extract_all(w, pattern)[[1]] ## Find all words starting with capital letter
CapitalWords <- append(CapitalWords, matches)
}
